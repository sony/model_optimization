{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Export Quantized Pytorch Model\n",
        "\n",
        "[Run this tutorial in Google Colab](https://colab.research.google.com/github/sony/model_optimization/blob/main/tutorials/notebooks/example_pytorch_export.ipynb)\n",
        "\n",
        "\n",
        "To export a Pytorch model as a quantized model, it is necessary to first apply quantization\n",
        "to the model using MCT:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UJDzewEYfSN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q mct-nightly"
      ],
      "metadata": {
        "id": "qNddNV6TEsX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import model_compression_toolkit as mct\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.models.mobilenetv2 import mobilenet_v2\n",
        "\n",
        "# Create a model\n",
        "float_model = mobilenet_v2()\n",
        "\n",
        "\n",
        "# Notice that here the representative dataset is random for demonstration only.\n",
        "def representative_data_gen():\n",
        "    yield [np.random.random((1, 3, 224, 224))]\n",
        "\n",
        "\n",
        "quantized_exportable_model, _ = mct.ptq.pytorch_post_training_quantization_experimental(float_model, representative_data_gen=representative_data_gen)"
      ],
      "metadata": {
        "id": "eheBYKxRDFgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ONNX\n",
        "\n",
        "The model will be exported in ONNX format where weights and activations are represented as float. Notice onnx should be installed in order to export the model to an onnx model."
      ],
      "metadata": {
        "id": "-n70LVe6DQPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q onnx"
      ],
      "metadata": {
        "id": "7sUSLA0bMOSY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two optional formats to choose: MCTQ or FAKELY_QUANT.\n",
        "\n",
        "#### MCTQ Quantization Format\n",
        "\n",
        "By default, `mct.exporter.pytorch_export_model` will export the quantized pytorch model to\n",
        "an onnx model with custom quantizers from mct_quantizers module.  \n",
        "\n"
      ],
      "metadata": {
        "id": "74i7Fi0kM0Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "# Path of exported model\n",
        "_, onnx_file_path = tempfile.mkstemp('.onnx')\n",
        "\n",
        "# Export onnx model with mctq quantizers.\n",
        "mct.exporter.pytorch_export_model(model=quantized_exportable_model,\n",
        "                                  save_model_path=onnx_file_path,\n",
        "                                  repr_dataset=representative_data_gen)"
      ],
      "metadata": {
        "id": "PO-Hh0bzD1VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the model has the same size as the quantized exportable model as weights data types are float.\n",
        "\n",
        "#### Fakely-Quantized\n",
        "\n",
        "To export a fakely-quantized model, use QuantizationFormat.FAKELY_QUANT:\n"
      ],
      "metadata": {
        "id": "Bwx5rxXDF_gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "# Path of exported model\n",
        "_, onnx_file_path = tempfile.mkstemp('.onnx')\n",
        "\n",
        "# Use QuantizationFormat.FAKELY_QUANT for fakely-quantized weights and activations.\n",
        "mct.exporter.pytorch_export_model(model=quantized_exportable_model,\n",
        "                                  save_model_path=onnx_file_path,\n",
        "                                  repr_dataset=representative_data_gen,\n",
        "                                  quantization_format=mct.exporter.QuantizationFormat.FAKELY_QUANT)"
      ],
      "metadata": {
        "id": "WLyHEEiwGByT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Notice that the fakely-quantized model has the same size as the quantized\n",
        "exportable model as weights data types are float.\n",
        "\n",
        "### TorchScript\n",
        "\n",
        "The model will be exported in TorchScript format where weights and activations are\n",
        "quantized but represented as float (fakely quant)."
      ],
      "metadata": {
        "id": "-L1aRxFGGFeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of exported model\n",
        "_, torchscript_file_path = tempfile.mkstemp('.pt')\n",
        "\n",
        "\n",
        "# Use mode PytorchExportSerializationFormat.TORCHSCRIPT a torchscript model\n",
        "# and QuantizationFormat.FAKELY_QUANT for fakely-quantized weights and activations.\n",
        "mct.exporter.pytorch_export_model(model=quantized_exportable_model,\n",
        "                                  save_model_path=torchscript_file_path,\n",
        "                                  repr_dataset=representative_data_gen,\n",
        "                                  serialization_format=mct.exporter.PytorchExportSerializationFormat.TORCHSCRIPT,\n",
        "                                  quantization_format=mct.exporter.QuantizationFormat.FAKELY_QUANT)"
      ],
      "metadata": {
        "id": "V4I-p1q5GLzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the fakely-quantized model has the same size as the quantized exportable model as weights data types are\n",
        "float."
      ],
      "metadata": {
        "id": "SBqtJV9AGRzN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7e1572"
      },
      "source": [
        "Copyright 2023 Sony Semiconductor Israel, Inc. All rights reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n"
      ]
    }
  ]
}
